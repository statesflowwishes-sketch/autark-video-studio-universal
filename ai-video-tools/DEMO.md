# ü§ñ KI-Video-Pipeline Demo

Vollautomatische Lernvideo-Erstellung mit 33+ Open-Source-Tools

## üéØ Was ist das?

Ein komplettes Setup zur automatischen Erstellung von **l√§ngeren Lernvideos** aus Text-Skripten mit:
- ‚úÖ Text-to-Speech (Sprache generieren)
- ‚úÖ Text-to-Video (KI-Videos erstellen) 
- ‚úÖ PC-Motherboard Animation (bereits vorhanden)
- ‚úÖ Automatisches Kombinieren zu langen Videos
- ‚úÖ 33+ Open-Source KI-Tools integriert

---

## üöÄ Schnellstart (5 Minuten)

### 1. **Alles installieren:**
```bash
cd ai-video-tools
python3 install_ai_tools.py
```

### 2. **Erstes Video erstellen:**
```bash
# Ihre Geschichte als Lernvideo
python3 full_pipeline.py \
  --script "../stories/spannende_geschichte.md" \
  --output "mein_erstes_ki_video" \
  --style "futuristic tutorial"
```

### 3. **Video ansehen:**
```bash
# Finales Video wird erstellt in:
# exports/mein_erstes_ki_video.mp4
```

---

## üìÅ Projekt-√úbersicht

```
üìÅ Ihr Multimedia-Projekt/
‚îú‚îÄ‚îÄ ü§ñ ai-video-tools/          # KI-Video-Pipeline
‚îÇ   ‚îú‚îÄ‚îÄ install_ai_tools.py     # Installiert alle 33+ Tools
‚îÇ   ‚îú‚îÄ‚îÄ full_pipeline.py        # Komplette Video-Pipeline
‚îÇ   ‚îú‚îÄ‚îÄ text-to-speech/         # TTS-Tools (Coqui, Bark, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ text-to-video/          # Video-KI (Stable Video, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ remotion-project/       # React-basierte Videos
‚îú‚îÄ‚îÄ üé≠ stories/                 # Ihre Geschichten & Skripte
‚îú‚îÄ‚îÄ üñ•Ô∏è web-animation/           # PC-Motherboard Animation
‚îú‚îÄ‚îÄ üìÅ exports/                 # Fertige Videos
‚îú‚îÄ‚îÄ üõ†Ô∏è scripts/                # Original Audio-Tools
‚îî‚îÄ‚îÄ üìö templates/               # Vorlagen
```

---

## üé¨ Verwendung der 33+ KI-Tools

### **End-to-End Frameworks:**
```bash
# Remotion (React-Videos, ‚àû L√§nge)
cd ai-video-tools/remotion-project
npx create-remotion-video

# MoviePy (Python, Video+Audio)
python3 -c "
from moviepy.editor import *
clip = VideoFileClip('input.mp4')
clip.write_videofile('output.mp4')
"

# Manim (Mathematische Animationen)
pip install manim
manim -pql scene.py MyMathScene
```

### **Text-to-Video KI-Modelle:**
```bash
# HunyuanVideo (Tencent, sehr stark)
huggingface-cli download Tencent-Hunyuan/HunyuanVideo

# Stable Video Diffusion
python3 text-to-video/stable_video_demo.py

# AnimateDiff (Bild-Sequenzen)
python3 text-to-video/animate_diff_demo.py

# CogVideo (Transformer-basiert)
python3 text-to-video/cogvideo_demo.py
```

### **Text-to-Speech:**
```bash
# Coqui TTS (Multi-language)
python3 text-to-speech/coqui_demo.py --text "Hallo Welt" --lang de

# Bark (KI-Stimmen mit Emotionen)
python3 text-to-speech/bark_demo.py --text "Spannende Geschichte!"

# ESPnet-TTS (Deep Learning)
python3 text-to-speech/espnet_demo.py
```

---

## üéØ Workflow-Beispiele

### **Workflow 1: Automatisches Tutorial**
```bash
# 1. Schreiben Sie tutorial.txt
echo "Heute lernen wir Python. Zuerst..." > tutorial.txt

# 2. Vollautomatisch zu Video
python3 full_pipeline.py --script tutorial.txt --style "educational"

# 3. Fertig! Video in exports/
```

### **Workflow 2: Mit PC-Animation kombiniert**
```bash
# 1. Ihre Geschichte + PC-Animation
python3 full_pipeline.py \
  --script "stories/spannende_geschichte.md" \
  --style "futuristic computer tutorial" \
  --duration 15

# 2. PC-Animation separat aufnehmen (OBS Studio)
# web-animation/motherboard.html im Browser
# Mit OBS aufnehmen als pc_animation.mp4

# 3. Beide Videos kombinieren
python3 combine_with_pc_animation.py \
  --main-video "exports/video.mp4" \
  --pc-animation "pc_animation.mp4" \
  --output "final_combo.mp4"
```

### **Workflow 3: L√§ngeres Lernvideo (10+ Minuten)**
```bash
# 1. Gro√ües Skript in Kapitel aufteilen
python3 split_long_script.py --input "long_tutorial.md" --chapters 5

# 2. Jedes Kapitel einzeln verarbeiten
for i in {1..5}; do
  python3 full_pipeline.py --script "chapter_$i.txt" --output "part_$i"
done

# 3. Alle Teile kombinieren
python3 combine_chapters.py --parts "part_*.mp4" --output "complete_course.mp4"
```

---

## üõ†Ô∏è Tool-Details

### **33+ Tools nach Kategorien:**

#### **1. Video-Frameworks (f√ºr lange Videos):**
- **Remotion** - React-basiert, ‚àû L√§nge ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **MoviePy** - Python, sehr flexibel ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Manim** - Mathematik/Wissenschaft ‚≠ê‚≠ê‚≠ê‚≠ê
- **OpenShot** - GUI + Scripting ‚≠ê‚≠ê‚≠ê

#### **2. KI Text-to-Video:**
- **HunyuanVideo** - Tencent, top Qualit√§t ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Stable Video Diffusion** - Stability AI ‚≠ê‚≠ê‚≠ê‚≠ê
- **CogVideo** - Transformer-basiert ‚≠ê‚≠ê‚≠ê‚≠ê
- **AnimateDiff** - Bild-Animation ‚≠ê‚≠ê‚≠ê‚≠ê
- **VideoCrafter2** - Diffusion ‚≠ê‚≠ê‚≠ê
- **Pika Labs** - Multi-Modal ‚≠ê‚≠ê‚≠ê
- **Mochi-1** - Kompakt ‚≠ê‚≠ê‚≠ê
- **SkyReels-V1** - Open Source ‚≠ê‚≠ê‚≠ê

#### **3. Text-to-Speech:**
- **Coqui TTS** - Multi-language ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
- **Bark** - Emotionale Stimmen ‚≠ê‚≠ê‚≠ê‚≠ê
- **ESPnet-TTS** - Deep Learning ‚≠ê‚≠ê‚≠ê‚≠ê

#### **4. Orchestrierung:**
- **BentoML** - Model Serving ‚≠ê‚≠ê‚≠ê‚≠ê
- **Haystack** - Q&A Integration ‚≠ê‚≠ê‚≠ê
- **DeepLake** - Data Management ‚≠ê‚≠ê‚≠ê

---

## üí° Performance-Tipps

### **GPU-Beschleunigung:**
```bash
# Pr√ºfen Sie GPU-Verf√ºgbarkeit
nvidia-smi

# CUDA f√ºr PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Modelle auf GPU laden
export CUDA_VISIBLE_DEVICES=0
```

### **Memory-Optimierung:**
```bash
# Gro√üe Modelle in Segmenten verarbeiten
python3 full_pipeline.py --batch-size 1 --max-length 100

# Temp-Files regelm√§√üig l√∂schen
python3 full_pipeline.py --cleanup
```

### **Qualit√§ts-Einstellungen:**
```json
// configs/high_quality.json
{
  "video_settings": {
    "resolution": "1920x1080",
    "fps": 30,
    "bitrate": "5M",
    "codec": "h264"
  },
  "ai_models": {
    "text_to_video": "hunyuan-video",
    "text_to_speech": "coqui-tts-high",
    "quality_level": "high"
  }
}
```

---

## üéØ F√ºr Ihr PC-Motherboard Projekt

### **Erweiterte PC-Animation:**
```bash
# 1. Bestehende Animation erweitern
python3 enhance_pc_animation.py \
  --input "web-animation/motherboard.html" \
  --ai-enhancement "stable-video-diffusion" \
  --style "cyberpunk futuristic computer" \
  --duration 60

# 2. Mit Ihrer Geschichte kombinieren
python3 full_pipeline.py \
  --script "stories/spannende_geschichte.md" \
  --background-animation "enhanced_pc.mp4" \
  --style "tech narrative"

# 3. Audio aus Downloads hinzuf√ºgen
python3 add_background_music.py \
  --video "exports/tech_story.mp4" \
  --music "/home/holythreekingstreescrowns/Downloads/Unbenannter Song.mp3" \
  --mix-level 0.3
```

---

## üöÄ Live-Demo starten

```bash
# Sofort verf√ºgbare Demo:
python3 full_pipeline.py \
  --script "../stories/spannende_geschichte.md" \
  --output "demo_video" \
  --style "futuristic tutorial" \
  --duration 10

# Ergebnis: exports/demo_video.mp4
```

---

**üéâ Ready f√ºr professionelle KI-Lernvideo-Produktion!**